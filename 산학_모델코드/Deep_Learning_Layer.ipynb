{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from math import atan, sqrt\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense, Reshape, Dropout, RepeatVector, LSTM, TimeDistributed, BatchNormalization, Bidirectional\n",
    "# import tensorflow_addons as tfa\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from numpy.random import seed\n",
    "import keras\n",
    "\n",
    "from transforms3d.axangles import axangle2mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Layer 구성\n",
    "\n",
    "def LSTM_model(input_shape, classes):\n",
    "    seed(2021)\n",
    "    tf.random.set_seed(2021)\n",
    "    \n",
    "    input_layer = tf.keras.layers.Input(input_shape)\n",
    "#     gru1 = L.LSTM(128, return_sequences = True, dropout = 0.5,kernel_regularizer=tf.keras.regularizers.L1(0.05))(input_layer)\n",
    "    gru1 = L.LSTM(128, return_sequences = True, dropout = 0.3)(input_layer)\n",
    "    mp = L.MaxPool1D(padding='same')(gru1)\n",
    "    ap = L.AveragePooling1D(padding='same')(gru1)\n",
    "    concat1 = L.Concatenate()([mp, ap])\n",
    "    \n",
    "    gru2 = L.LSTM(64, return_sequences = True, dropout = 0.2)(concat1)\n",
    "    mp2 = L.MaxPool1D(padding='same')(gru2)\n",
    "    ap2 = L.AveragePooling1D(padding='same')(gru2)\n",
    "    concat2 = L.Concatenate()([mp2, ap2])\n",
    "    \n",
    "    gru3 = L.LSTM(64, return_sequences = True)(concat2)\n",
    "    GAP = L.GlobalAveragePooling1D()(gru3)\n",
    "\n",
    "    dense = L.Dense(classes, activation = \"softmax\")(GAP)\n",
    "    \n",
    "    model = tf.keras.models.Model(input_layer, dense)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_data Shape 변환\n",
    "\n",
    "train_data = train_sc.iloc[:,1:]\n",
    "train_data = np.array(train_data)\n",
    "train_data = train_data.reshape(-1,10,9)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_data Label Shape 변환\n",
    "\n",
    "y = train_labels['label'].values\n",
    "y = tf.keras.utils.to_categorical(train_labels['label']) \n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kfold 를 이용해서 검증 데이터를 옮겨가면서 지속적인 학습을 진행 \n",
    "skf = StratifiedKFold(n_splits = 5, random_state = 2048, shuffle = True)\n",
    "\n",
    "# keras의 콜백함수인 ReduceLROnPlateau는 학습률이 개선되지 않을 때, \n",
    "# 학습률을 동적으로 조정하여 학습률을 개선하는 효과를 기대할 수 있습니다.\n",
    "reLR = ReduceLROnPlateau(monitor = 'loss', patience = 5,verbose = 1,factor = 0.8) \n",
    "\n",
    "# loss값이 개선되지 않는 일정 점에서 동작을 정지하여 리소스 확보를 돕는다.\n",
    "es = EarlyStopping(monitor='loss', patience=10, mode='min')\n",
    "\n",
    "window = 10\n",
    "columns = 9\n",
    "\n",
    "accuracy = []\n",
    "losss = []\n",
    "models = []\n",
    "\n",
    "# fold 에 따른 각각의 값 loss, accuracy, model 을 저장하기 위한 list 선언\n",
    "for i, (train, validation) in enumerate(skf.split(train_data, y.argmax(1))) :\n",
    "    \n",
    "    print(\"-\" * 20 +\"Fold_\"+str(i+1)+ \"-\" * 20)\n",
    "\n",
    "    model = LSTM_model((window,columns), 10)\n",
    "\n",
    "    history = model.fit(train_data[train], y[train],\n",
    "                        epochs = 300, \n",
    "                        verbose=0,\n",
    "                        batch_size=64,\n",
    "                        callbacks=[es, reLR])\n",
    "    \n",
    "    k_accuracy = '%.4f' % (model.evaluate(train_data[validation], y[validation])[1])\n",
    "    k_loss = '%.4f' % (model.evaluate(train_data[validation], y[validation])[0])\n",
    "    \n",
    "\n",
    "    accuracy.append(k_accuracy)\n",
    "    losss.append(k_loss)\n",
    "    models.append(model)\n",
    "\n",
    "# fold 진행하고 나서 나온 값을 위에 선언한 List에 appand한다. \n",
    "\n",
    "print('\\nK-fold cross validation Auc: {}'.format(accuracy))\n",
    "print('\\nK-fold cross validation loss: {}'.format(losss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 평균 정확도와 손실값 출력\n",
    "print(sum([float(i) for i in accuracy])/5)\n",
    "print()\n",
    "print(sum([float(i) for i in losss])/5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for model in models:\n",
    "    pred = model.predict(x_test)\n",
    "    preds.append(pred)\n",
    "pred = np.mean(preds, axis=0)\n",
    "pred_df = pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "for i in range(len(pred_df)):\n",
    "  temp_list.append(pred_df.iloc[i].argmax())\n",
    "\n",
    "result_df = pd.DataFrame(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  }
 ]
}